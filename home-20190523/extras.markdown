---
layout: default
---

# Good practices for HPC and Cloud 2019-05-23 <br/> Extras

<div style="float:right;max-width:205px;" markdown="1">
![NLeSC logo](/images/escience_center_logo.png)

![SURFsara logo](/images/SURFsara_logo.png)
</div>

This is part Extras of the tutorial [Good practices for HPC and Cloud 2019-05-23](.). These exercises can be done in any order and you are to do as many as you want, depending on your enthusiasm and available time.

You will find several _Food for brain_ questions in each exercise about situations that you might encounter when working with **Parallel programming** techniques. Our advice is that you perform many tests, observe the results (write down execution times, change parameters, make tables, draw graphs...) and think about your answers.

>**NOTE:**
>
> You should have completed (and understood) both [Part A](partA) and [Part B](partB) before trying these extras. Applying what you learned in [Part C](partC) may also be handy.

## Simple scalability

Link: [Simple Scalability: Principal Component Analysis (PCA)](PCA)
  
  Working with a real dataset on a real problem to look into the possibilities of easily scaling up and/or out.

## OpenMP

Link: [OpenMP: calculating _&pi;_](OpenMP)
  
  Using a simple algorithm to calculate _&pi;_ as an example, you will see the impact of the **scale-up** model and parallel programming with OpenMP.

## MPI

Link: [MPI: Wave equation](MPI)

  Using a numerical method to calculate wave propagation as an example, you will see the impact of both **scale-up** and **scale-out** models and parallel programming with MPI.
  
## XML-RPC

Link: [XML-RPC](XMLRPC)
  
  Experience the automation API that OpenNebula provides, which can be used to find out a lot of information about your own environment, and to operate with VMs in a non-interactive way.